kind: ConfigMap
apiVersion: v1
metadata:
  name: ebpf-exporter-config
  namespace: ebpf-exporter
data:
  config.yaml: |-
    programs:
      - name: tcpsynbl
        metrics:
          histograms:
            - name: tcp_syn_backlog
              help: TCP SYN backlog size
              table: bucket
              bucket_type: linear
              bucket_min: 0
              bucket_max: 20
              bucket_multiplier: 50
              labels:
                - name: bucket
                  size: 8
                  decoders:
                    - name: uint
        kprobes:
          tcp_v4_syn_recv_sock: do_count
          tcp_v6_syn_recv_sock: do_count
        code: |
          #include <net/sock.h>
          // Histograms to record TCP SYN backlog size
          BPF_HISTOGRAM(bucket, u64);
          int do_count(struct pt_regs *ctx, struct sock *sk) {
              u64 backlog = bpf_log2l(sk->sk_ack_backlog);
              bucket.increment(backlog);
              return 0;
          }
      - name: syslat
        metrics:
          histograms:
            - bucket_keys:
                - 100 # 100us
                - 1000 # 1ms
                - 250000 # 250ms
                - 1000000 # 1s
                - 2500000 # 2.5s
                - 5000000 # 5s
              bucket_multiplier: 1e-06
              bucket_type: fixed
              help: Latency of Linux syscalls
              labels:
                - decoders:
                    - name: ksym
                  name: function
                  size: 8
                - decoders:
                    - name: uint
                  name: bucket
                  size: 8
              name: syscall_latency_seconds
              table: dist
        kprobes:
          do_syscall_64: trace_func_entry
          syscall_slow_exit_work: trace_func_entry
          # Other options:
          # SyS_accept: trace_func_entry
          # SyS_accept4: trace_func_entry
          # SyS_connect: trace_func_entry
        kretprobes:
          do_syscall_64: trace_func_return
          syscall_slow_exit_work: trace_func_return
          # Other options:
          # SyS_accept: trace_func_return
          # SyS_accept4: trace_func_return
          # SyS_connect: trace_func_return
        code: |
          #include <uapi/linux/ptrace.h>
          // Set up user-defined buckets.
          const static u64 buckets[] = {100, 1000, 250000, 1000000, 2500000, 5000000};
          const static int NUM_BUCKETS = sizeof(buckets) / sizeof(buckets[0]);
          // Define the key used in the latency histogram.
          typedef struct hist_key {
              u64 ip;
              u64 bucket;
          } hist_key_t;
          // Used to keep track of the start time of syscalls.
          BPF_HASH(start, u32);
          // Used to keep track of the address of the syscall kprobe (e.g. do_syscall_64).
          BPF_HASH(ipaddr, u32);
          // Used to record the latency of syscalls.
          BPF_HISTOGRAM(dist, hist_key_t);
          static u64 get_bucket_key(u64 value) {
              for (int i = 0; i < NUM_BUCKETS; i++) {
                  if (value <= buckets[i]) {
                      return buckets[i];
                  }
              }
              // Cap at maximum value
              return buckets[NUM_BUCKETS-1];
          }
          // Called when a syscall kprobe is entered.
          int trace_func_entry(struct pt_regs *ctx) {
              // Get the process ID that resulted in this syscall kprobe.
              u64 pid_tgid = bpf_get_current_pid_tgid();
              u32 pid = pid_tgid;
              // Get and record the current kernel time (in nanoseconds).
              u64 ts = bpf_ktime_get_ns();
              start.update(&pid, &ts);
              // Get and record the kprobe address.
              u64 ip = PT_REGS_IP(ctx);
              ipaddr.update(&pid, &ip);
              return 0;
          }
          // Called when a syscall kprobe returns.
          int trace_func_return(struct pt_regs *ctx) {
              // Get the process ID that resulted in this syscall kprobe.
              u64 pid_tgid = bpf_get_current_pid_tgid();
              u32 pid = pid_tgid;
              // Will be used to retrieve start time and calculate latency.
              u64 *tsp, delta;
              // Retrieve the start time that was stored in trace_func_entry.
              tsp = start.lookup(&pid);
              // Return is no start time was found.
              if (tsp == 0) {
                  return 0;
              }
              // Calculate the latency of the syscall.
              delta = bpf_ktime_get_ns() - *tsp;
              // Convert to microseconds.
              delta /= 1000;
              // Remove the start time from the hash.
              start.delete(&pid);
              // Retrieve the kprobe address.
              u64 ip, *ipp = ipaddr.lookup(&pid);
              // Return if kprobe address not found.
              if (ipp == 0) {
                  return 0;
              }
              ip = *ipp;
              // Construct histogram key.
              hist_key_t key;
              // From ebpf_exporter docs:
              // > Note that sometimes you can observe PT_REGS_IP being off by one.
              // > You can subtract 1 in your code to make it point to the right
              // > instruction that can be found /proc/kallsyms.
              key.ip = ip - 1;
              // Get the user-defined bucket of the latency, and increment the
              // slot for that value in the latency histogram.
              key.bucket = get_bucket_key(delta);
              dist.increment(key);
              // Increment the optional sum key.
              hist_key_t max_key;
              max_key.bucket = buckets[NUM_BUCKETS - 1] + 1;
              max_key.ip = key.ip;
              dist.increment(max_key, delta);
              // Delete the kprobe address from the hash.
              ipaddr.delete(&pid);
              return 0;
          }
      - name: runqlat
        metrics:
          histograms:
            - name: run_queue_latency_seconds
              help: Run queue latency histogram
              table: run_queue_latencty
              bucket_type: exp2
              bucket_min: 0
              bucket_max: 26
              bucket_multiplier: 0.000001 # microseconds to seconds
              labels:
                - name: bucket
                  size: 8
                  decoders:
                    - name: uint
        kprobes:
          ttwu_do_wakeup: trace_ttwu_do_wakeup
          wake_up_new_task: trace_wake_up_new_task
          finish_task_switch: trace_run
        code: |
          #include <linux/sched.h>
          // 27 buckets for latency, max range is 33.6s .. 67.1s
          const u8 max_latency_slot = 26;
          // Histograms to record latencies
          BPF_HISTOGRAM(run_queue_latencty, u64, max_latency_slot + 2);
          // Pid to enqueue time map
          BPF_HASH(start, u32);
          // Record enqueue timestamp
          static int trace_enqueue(u32 tgid, u32 pid) {
              if (tgid == 0 && pid == 0) {
                  // Skip swapper kthread
                  return 0;
              }
              u64 ts = bpf_ktime_get_ns();
              start.update(&pid, &ts);
              return 0;
          }
          int trace_wake_up_new_task(struct pt_regs *ctx, struct task_struct *p) {
              return trace_enqueue(p->tgid, p->pid);
          }
          int trace_ttwu_do_wakeup(struct pt_regs *ctx, void* rq, struct task_struct *p, int wake_flags) {
              return trace_enqueue(p->tgid, p->pid);
          }
          // Calculate latency
          int trace_run(struct pt_regs *ctx, struct task_struct *prev) {
              // Treat like an enqueue event and store timestamp
              if (prev->state == TASK_RUNNING) {
                  trace_enqueue(prev->tgid, prev->pid);
              }
              u32 tgid = bpf_get_current_pid_tgid() >> 32;
              u32 pid = bpf_get_current_pid_tgid();
              // Fetch timestamp and calculate delta
              u64 *tsp = start.lookup(&pid);
              if (tsp == 0) {
                  // Missed enqueue
                  return 0;
              }
              // Latency in microseconds
              u64 latency_us = (bpf_ktime_get_ns() - *tsp) / 1000;
              // Latency histogram key
              u64 latency_slot = bpf_log2l(latency_us);
              // Cap latency bucket at max value
              if (latency_slot > max_latency_slot) {
                  latency_slot = max_latency_slot;
              }
              // Increment bucket key
              run_queue_latencty.increment(latency_slot);
              // Increment sum key
              run_queue_latencty.increment(max_latency_slot + 1, latency_us);
              // Remove enqueued task
              start.delete(&pid);
              return 0;
          }
      - name: bio
        metrics:
          histograms:
            - name: bio_latency_seconds
              help: Block IO latency histogram
              table: io_latency
              bucket_type: exp2
              bucket_min: 0
              bucket_max: 26
              bucket_multiplier: 0.000001 # microseconds to seconds
              labels:
                - name: device
                  size: 4
                  decoders:
                    - name: majorminor
                - name: operation
                  size: 4
                  decoders:
                    - name: uint
                    - name: static_map
                      static_map:
                        1: read
                        2: write
                - name: bucket
                  size: 8
                  decoders:
                    - name: uint
            - name: bio_size_bytes
              help: Block IO size histogram with kibibyte buckets
              table: io_size
              bucket_type: exp2
              bucket_min: 0
              bucket_max: 15
              bucket_multiplier: 1024 # kibibytes to bytes
              labels:
                - name: device
                  size: 4
                  decoders:
                    - name: majorminor
                - name: operation
                  size: 4
                  decoders:
                    - name: uint
                    - name: static_map
                      static_map:
                        1: read
                        2: write
                - name: bucket
                  size: 8
                  decoders:
                    - name: uint
        tracepoints:
          block:block_rq_issue: tracepoint__block__block_rq_issue
          block:block_rq_complete: tracepoint__block__block_rq_complete
        code: |
          #include <linux/blkdev.h>
          typedef struct disk_key {
              u32 dev;
              u8 op;
              u64 slot;
          } disk_key_t;
          // Max number of disks we expect to see on the host
          const u8 max_disks = 255;
          // 27 buckets for latency, max range is 33.6s .. 67.1s
          const u8 max_latency_slot = 26;
          // 16 buckets per disk in kib, max range is 16mib .. 32mib
          const u8 max_size_slot = 15;
          // Histograms to record latencies
          BPF_HISTOGRAM(io_latency, disk_key_t, (max_latency_slot + 2) * max_disks);
          // Histograms to record sizes
          BPF_HISTOGRAM(io_size, disk_key_t, (max_size_slot + 2) * max_disks);
          struct key_t {
              dev_t dev;
              sector_t sector;
          };
          struct val_t {
              u64 start;
              u64 bytes;
          };
          // Hash to temporily hold the start time of each bio request, max 10k in-flight by default
          BPF_HASH(start, struct key_t, struct val_t);
          // Generates function tracepoint__block__block_rq_issue
          TRACEPOINT_PROBE(block, block_rq_issue) {
              // blkid generates these and we're not interested in them
              if (args->dev == 0) {
                  return 0;
              }
              struct key_t key = {};
              key.dev = args->dev;
              key.sector = args->sector;
              if (key.sector == -1) {
                key.sector = 0;
              }
              struct val_t val = {};
              val.start = bpf_ktime_get_ns();
              val.bytes = args->bytes;
              start.update(&key, &val);
              return 0;
          }
          // Generates function tracepoint__block__block_rq_complete
          TRACEPOINT_PROBE(block, block_rq_complete) {
              struct key_t key = {};
              key.dev = args->dev;
              key.sector = args->sector;
              if (key.sector == -1) {
                key.sector = 0;
              }
              struct val_t *valp = start.lookup(&key);
              if (valp == 0) {
                  return 0; // missed issue
              }
              // Delta in microseconds
              u64 delta = (bpf_ktime_get_ns() - valp->start) / 1000;
              // Latency histogram key
              u64 latency_slot = bpf_log2l(delta);
              // Cap latency bucket at max value
              if (latency_slot > max_latency_slot) {
                  latency_slot = max_latency_slot;
              }
              disk_key_t latency_key = {};
              latency_key.slot = latency_slot;
              latency_key.dev = new_encode_dev(args->dev);
              // Size in kibibytes
              u64 size_kib = valp->bytes / 1024;
              // Request size histogram key
              u64 size_slot = bpf_log2(size_kib);
              // Cap latency bucket at max value
              if (size_slot > max_size_slot) {
                  size_slot = max_size_slot;
              }
              disk_key_t size_key = {};
              size_key.slot = size_slot;
              size_key.dev = new_encode_dev(args->dev);
              if (args->rwbs[0] == 'W' || args->rwbs[0] == 'S' || args->rwbs[0] == 'F' || args->rwbs[1] == 'W' || args->rwbs[1] == 'S' || args->rwbs[1] == 'F') {
                  latency_key.op = 2;
                  size_key.op    = 2;
              } else {
                  latency_key.op = 1;
                  size_key.op    = 1;
              }
              io_latency.increment(latency_key);
              io_size.increment(size_key);
              // Increment sum keys
              latency_key.slot = max_latency_slot + 1;
              io_latency.increment(latency_key, delta);
              size_key.slot = max_size_slot + 1;
              io_size.increment(size_key, size_kib);
              start.delete(&key);
              return 0;
          }
